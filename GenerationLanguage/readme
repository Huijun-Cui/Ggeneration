这部分代码用的数据是DSTC2数据，完成的任务是基于槽信息生成自然语言任务。所用的模型是SC-LSTM。
这是一个完整的实现，主要解决三个方面的问题：
1.数据的处理。
2.批量训练中解决了sequence to sequence任务中，变长序列如何训练的问题。
3.解决了，语言生成中如何批生成，再进行批rerank。

模型实现是很简单的，但是我们在实践过程中会碰到很多模型以外的问题。
第一个问题就是特征表达，如果特征处理不好，模型再好也难以取得满意的效果。
第二是批量训练，因为输入序列是变长的，如果想批训练，必须长度对其，必须对短的句子进行填充，如何让这些填充符号不影响模型的学习是必须要解决的问题，
我这个代码里已经很好地解决了这个问题。
第三个问题是语言生成的时候，如何批量生成又批量rerank，熟悉NLG的朋友对rarank自然不会陌生。对不熟悉的人，我简单介绍下，rerank就是用其他模型对
生成句子进行打分，这个打分标准可以很多，我在这里用的是用句子生成概率来进行打分。其实rerank就是一种模型融合。我们知道语言生成是以前一个生成词作
为下一时刻的输入，遇到停止符就会停止生成。所以各个句子生成长度不一样的。我们如何对这样的情况进行反向打分呢？ 我在这里已经解决了这一个问题。
里面还有对多进程语言生成的尝试，MutiProcessBleu（）。发现效果并不是很好，速度跟原来差不多，所以就没有用。
